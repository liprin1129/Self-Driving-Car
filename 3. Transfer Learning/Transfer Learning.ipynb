{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Table of contents\n",
    "1. [Transfer Learning with TensorFlow](#Transfer Learning with TensorFlow)\n",
    "    1. [ImageNet Inference](#ImageNet Inference)\n",
    "    2. [Traffic Sign Inference](#Traffic Sign Inference)\n",
    "    3. [Feature Extraction](#Feature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Transfer Learning with TensorFlow <a name='Transfer Learning with TensorFlow'></a>\n",
    "\n",
    "__Transfer learning__ is the practice of starting with a network that has already been trained, and then applying that network to your own problem.\n",
    "\n",
    "Because neural networks can often take days or even weeks to train, transfer learning (i.e. starting with a network that somebody else has already trained) can greatly shorten training time.\n",
    "\n",
    "How do we apply transfer learning? Two popular methods are __feature extraction__ and __finetuning__.\n",
    "\n",
    "1. __Feature extraction__. Take a pretrained neural network and replace the final (classification) layer with a new classification layer, or perhaps even a small feedforward network that ends with a new classification layer. During training the weights in all the pre-trained layers are frozen, so only the weights for the new layer(s) are trained. In other words, the gradient doesn't flow backwards past the first new layer.\n",
    "2. __Finetuning__. This is similar to feature extraction except the pre-trained weights aren't frozen. The network is trained end-to-end.\n",
    "\n",
    "The labs in this lesson will focus on feature extraction since it's less computationally intensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. ImageNet Inference <a name='ImageNet Inference'></a>\n",
    "\n",
    "<img src='Images/ImageNet Inference.png' width=200>\n",
    "$$ \\text{top: Poodle, bottom: Weasel} $$\n",
    "\n",
    "To start, run __imagenet_inference.py__, and verify that the network classifies the images correctly.\n",
    "\n",
    "```Python\n",
    "python imagenet_inference.py\n",
    "```\n",
    "\n",
    "The output should look similar to this:\n",
    "```Python\n",
    "Image 0\n",
    "miniature poodle: 0.389\n",
    "toy poodle: 0.223\n",
    "Bedlington terrier: 0.173\n",
    "standard poodle: 0.150\n",
    "komondor: 0.026\n",
    "\n",
    "Image 1\n",
    "weasel: 0.331\n",
    "polecat, fitch, foulmart, foumart, Mustela putorius: 0.280\n",
    "black-footed ferret, ferret, Mustela nigripes: 0.210\n",
    "mink: 0.081\n",
    "Arctic fox, white fox, Alopex lagopus: 0.027\n",
    "\n",
    "Time: 5.587 seconds\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.  Traffic Sign Inference <a name='Traffic Sign Inference'></a>\n",
    "\n",
    "<img src='Images/Traffic Sign Inference.png' width=200>\n",
    "$$ \\text{top: construction sign, bottom: stop sign} $$\n",
    "\n",
    "Next, run python __traffic_sign_inference.py__, and see how well the classifier performs on the example construction and stop signs.\n",
    "\n",
    "OH NO!\n",
    "\n",
    "AlexNet expects a 227x227x3 pixel image, whereas the traffic sign images are 32x32x3 pixels.\n",
    "\n",
    "In order to feed the traffic sign images into AlexNet, you'll need to resize the images to the dimensions that AlexNet expects.\n",
    "\n",
    "You could resize the images outside of this program, but that approach doesn't scale well. Instead, use the [tf.image.resize_images](https://www.tensorflow.org/api_guides/python/image#Resizing) method to resize the images as they are fed into the model.\n",
    "\n",
    "Open up __traffic_sign_inference.py__ and complete the __TODO(s)__.\n",
    "\n",
    "The output should look similar to this:\n",
    "```Python\n",
    "Image 0\n",
    "screen, CRT screen: 0.051\n",
    "digital clock: 0.041\n",
    "laptop, laptop computer: 0.030\n",
    "balance beam, beam: 0.027\n",
    "parallel bars, bars: 0.023\n",
    "\n",
    "Image 1\n",
    "digital watch: 0.395\n",
    "digital clock: 0.275\n",
    "bottlecap: 0.115\n",
    "stopwatch, stop watch: 0.104\n",
    "combination lock: 0.086\n",
    "\n",
    "Time: 0.592 seconds\n",
    "```\n",
    "\n",
    "__Quiz:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The traffic signs are 32x32 so you\n",
    "have to resize them to be 227x227 before\n",
    "passing them to AlexNet.\n",
    "\"\"\"\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from caffe_classes import class_names\n",
    "from alexnet import AlexNet\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "# TODO: Resize the images so they can be fed into AlexNet.\n",
    "# HINT: Use `tf.image.resize_images` to resize the images\n",
    "resized = tf.image.resize_images(x, (227, 227))\n",
    "\n",
    "assert resized is not Ellipsis, \"resized needs to modify the placeholder image size to (227,227)\"\n",
    "probs = AlexNet(resized)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = imread(\"construction.jpg\").astype(np.float32)\n",
    "im1 = im1 - np.mean(im1)\n",
    "\n",
    "im2 = imread(\"stop.jpg\").astype(np.float32)\n",
    "im2 = im2 - np.mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = np.argsort(output)[input_im_ind, :]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__\n",
    "```Python\n",
    "\"\"\"\n",
    "The traffic signs are 32x32 so you\n",
    "have to resize them to be 227x227 before\n",
    "passing them to AlexNet.\n",
    "\"\"\"\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from caffe_classes import class_names\n",
    "from alexnet import AlexNet\n",
    "\n",
    "\n",
    "# placeholders\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "resized = tf.image.resize_images(x, (227, 227))\n",
    "\n",
    "probs = AlexNet(resized)\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = imread(\"construction.jpg\").astype(np.float32)\n",
    "im1 = im1 - np.mean(im1)\n",
    "\n",
    "im2 = imread(\"stop.jpg\").astype(np.float32)\n",
    "im2 = im2 - np.mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = np.argsort(output)[input_im_ind, :]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time() - t))\n",
    "```\n",
    "\n",
    "The notable part being:\n",
    "```Python\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "resized = tf.image.resize_images(x, (227, 227))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Feature Extraction <a name='Feature Extraction'></a>\n",
    "\n",
    "The problem is that AlexNet was trained on the [ImageNet](http://www.image-net.org/) database, which has 1000 classes of images. We can see the classes in the __caffe_classes.py__ file. None of those classes involves traffic signs.\n",
    "\n",
    "In order to successfully classify our traffic sign images, we need to remove the final, 1000-neuron classification layer and replace it with a new, 43-neuron classification layer.\n",
    "\n",
    "This is called _feature extraction_, because we're basically extracting the image features inferred by the penultimate layer, and passing these features to a new classification layer.\n",
    "\n",
    "Open __feature_extraction.py__ and complete the __TODO(s)__.\n",
    "\n",
    "The output will probably not precisely match the sample output below, since the output will depend on the (probably random) initialization of weights in the network. That being said, the output classes you see should be present in __signnames.csv__.\n",
    "\n",
    "```Python\n",
    "Image 0\n",
    "Double curve: 0.059\n",
    "Ahead only: 0.048\n",
    "Road work: 0.047\n",
    "Dangerous curve to the right: 0.047\n",
    "Road narrows on the right: 0.039\n",
    "\n",
    "Image 1\n",
    "General caution: 0.079\n",
    "No entry: 0.067\n",
    "Dangerous curve to the right: 0.054\n",
    "Speed limit (50km/h): 0.053\n",
    "Ahead only: 0.048\n",
    "\n",
    "Time: 0.500 seconds\n",
    "```\n",
    "\n",
    "__Quiz:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from alexnet import AlexNet\n",
    "\n",
    "sign_names = pd.read_csv('signnames.csv')\n",
    "nb_classes = 43\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "resized = tf.image.resize_images(x, (227, 227))\n",
    "\n",
    "# NOTE: By setting `feature_extract` to `True` we return\n",
    "# the second to last layer.\n",
    "fc7 = AlexNet(resized, feature_extract=True)\n",
    "# TODO: Define a new fully connected layer followed by a softmax activation to classify\n",
    "# the traffic signs. Assign the result of the softmax activation to `probs` below.\n",
    "# HINT: Look at the final layer definition in alexnet.py to get an idea of what this\n",
    "# should look like.\n",
    "shape = (fc7.get_shape().as_list()[-1], nb_classes)  # use this shape for the weight matrix\n",
    "\n",
    "fc8W = tf.Variable(tf.truncated_normal([4096, 43], stddev=1e-2))\n",
    "fc8b = tf.Variable(tf.zeros(nb_classes))\n",
    "logits = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "probs = tf.nn.softmax(logits)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = imread(\"construction.jpg\").astype(np.float32)\n",
    "im1 = im1 - np.mean(im1)\n",
    "\n",
    "im2 = imread(\"stop.jpg\").astype(np.float32)\n",
    "im2 = im2 - np.mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = np.argsort(output)[input_im_ind, :]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (sign_names.ix[inds[-1 - i]][1], output[input_im_ind, inds[-1 - i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__\n",
    "```Python\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from alexnet import AlexNet\n",
    "\n",
    "sign_names = pd.read_csv('signnames.csv')\n",
    "nb_classes = 43\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "resized = tf.image.resize_images(x, (227, 227))\n",
    "\n",
    "# Returns the second final layer of the AlexNet model,\n",
    "# this allows us to redo the last layer specifically for \n",
    "# traffic signs model.\n",
    "fc7 = AlexNet(resized, feature_extract=True)\n",
    "shape = (fc7.get_shape().as_list()[-1], nb_classes)\n",
    "fc8W = tf.Variable(tf.truncated_normal(shape, stddev=1e-2))\n",
    "fc8b = tf.Variable(tf.zeros(nb_classes))\n",
    "logits = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "probs = tf.nn.softmax(logits)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = imread(\"construction.jpg\").astype(np.float32)\n",
    "im1 = im1 - np.mean(im1)\n",
    "\n",
    "im2 = imread(\"stop.jpg\").astype(np.float32)\n",
    "im2 = im2 - np.mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = np.argsort(output)[input_im_ind, :]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (sign_names.ix[inds[-1 - i]][1], output[input_im_ind, inds[-1 - i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time() - t))\n",
    "```\n",
    "\n",
    "The notable part being:\n",
    "\n",
    "```Python\n",
    "# Returns the second final layer of the AlexNet model,\n",
    "# this allows us to redo the last layer specifically for \n",
    "# traffic signs model.\n",
    "fc7 = AlexNet(resized, feature_extract=True)\n",
    "shape = (fc7.get_shape().as_list()[-1], nb_classes)\n",
    "fc8W = tf.Variable(tf.truncated_normal(shape, stddev=1e-2))\n",
    "fc8b = tf.Variable(tf.zeros(nb_classes))\n",
    "logits = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "probs = tf.nn.softmax(logits)\n",
    "```\n",
    "\n",
    "First, I figure out the shape of the final fully connected layer, in my opinion this is the trickiest part. To do that I have to figure out the size of the output from __fc7__. Since it's a fully connected layer I know it's shape will be 2D so the second (or last) element of the list will be the size of the output. __fc7.get_shape().as_list()[-1]__ does the trick. I then combine this with the number of classes for the Traffic Sign dataset to get the shape of the final fully connected layer, __shape = (fc7.get_shape().as_list()[-1], nb_classes)__. The rest of the code is just the standard way to define a fully connected in TensorFlow. Finally, I calculate the probabilities via softmax, __probs = tf.nn.softmax(logits)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. Training the Feature Extractor <a name='Training the Feature Extractor'></a>\n",
    "\n",
    "The feature extractor we just created works, in the sense that data will flow through the network and result in predictions.\n",
    "\n",
    "But the predictions aren't accurate, because we haven't yet trained the new classification layer.\n",
    "\n",
    "In order to do that, we'll need to read in the training dataset and train the network.\n",
    "\n",
    "Training AlexNet (even just the final layer!) can take a little while, so if we don't have a GPU, running on a subset of the data is a good alternative. As a point of reference one epoch over the training set takes roughly 53-55 seconds with a GTX 970.\n",
    "\n",
    "Open up __train_feature_extraction.py__ and complete the __TODO(s)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from alexnet import AlexNet\n",
    "\n",
    "nb_classes = 43\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# TODO: Load traffic signs data.\n",
    "file_name = 'Data/train.p'\n",
    "with open(file_name, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# TODO: Split data into training and validation sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['features'], data['labels'], test_size=0.33, random_state=42)\n",
    "\n",
    "# TODO: Define placeholders and resize operation.\n",
    "features = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "labels = tf.placeholder(tf.int64, None)\n",
    "resized = tf.image.resize_images(features, (227, 227))\n",
    "\n",
    "# TODO: pass placeholder as first argument to `AlexNet`.\n",
    "fc7 = AlexNet(resized, feature_extract=True)\n",
    "# NOTE: `tf.stop_gradient` prevents the gradient from flowing backwards\n",
    "# past this point, keeping the weights before and up to `fc7` frozen.\n",
    "# This also makes training faster, less work to do!\n",
    "fc7 = tf.stop_gradient(fc7)\n",
    "\n",
    "# TODO: Add the final layer for traffic sign classification.\n",
    "shape = (fc7.get_shape().as_list()[-1], nb_classes)\n",
    "print(shape)\n",
    "fc8W = tf.Variable(tf.truncated_normal(shape, stddev=1e-2))\n",
    "fc8b = tf.Variable(tf.zeros(nb_classes))\n",
    "logits = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "probs = tf.nn.softmax(logits)\n",
    "\n",
    "# TODO: Define loss, training, accuracy operations.\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "loss_op = tf.reduce_mean(cross_entropy)\n",
    "opt = tf.train.AdamOptimizer()\n",
    "train_op = opt.minimize(loss_op, var_list=[fc8W, fc8b])\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# HINT: Look back at your traffic signs project solution, you may\n",
    "# be able to reuse some the code.\n",
    "preds = tf.arg_max(logits, 1)\n",
    "accuracy_op = tf.reduce_mean(tf.cast(tf.equal(preds, labels), tf.float32))\n",
    "\n",
    "# TODO: Train and evaluate the feature extraction model.\n",
    "def eval_on_data(X, y, sess):\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    for offset in range(0, X.shape[0], batch_size):\n",
    "        end = offset + batch_size\n",
    "        X_batch = X[offset:end]\n",
    "        y_batch = y[offset:end]\n",
    "\n",
    "        loss, acc = sess.run([loss_op, accuracy_op], feed_dict={features: X_batch, labels: y_batch})\n",
    "        total_loss += (loss * X_batch.shape[0])\n",
    "        total_acc += (acc * X_batch.shape[0])\n",
    "\n",
    "    return total_loss/X.shape[0], total_acc/X.shape[0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "\n",
    "    for i in tqdm(range(epochs)):\n",
    "        # training\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        t0 = time.time()\n",
    "        for offset in range(0, X_train.shape[0], batch_size):\n",
    "            end = offset + batch_size\n",
    "            sess.run(train_op, feed_dict={features: X_train[offset:end], labels: y_train[offset:end]})\n",
    "\n",
    "        val_loss, val_acc = eval_on_data(X_val, y_val, sess)\n",
    "        print(\"Epoch\", i+1)\n",
    "        print(\"Time: %.3f seconds\" % (time.time() - t0))\n",
    "        print(\"Validation Loss =\", val_loss)\n",
    "        print(\"Validation Accuracy =\", val_acc)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Most of the code should look familiar.\n",
    "```Python\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels)\n",
    "loss_op = tf.reduce_mean(cross_entropy)\n",
    "opt = tf.train.AdamOptimizer()\n",
    "train_op = opt.minimize(loss_op, var_list=[fc8W, fc8b])\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "preds = tf.arg_max(logits, 1)\n",
    "accuracy_op = tf.reduce_mean(tf.cast(tf.equal(preds, labels), tf.float32))\n",
    "```\n",
    "\n",
    "Here are all the operations are defined (training, loss, accuracy, etc); eval_on_data is a utility function to calculate the loss and accuracy over a dataset to evaluate all at once.\n",
    "```Python\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # training\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        t0 = time.time()\n",
    "        for offset in range(0, X_train.shape[0], batch_size):\n",
    "            end = offset + batch_size\n",
    "            sess.run(train_op, feed_dict={features: X_train[offset:end], labels: y_train[offset:end]})\n",
    "\n",
    "        val_loss, val_acc = eval_on_data(X_val, y_val, sess)\n",
    "        print(\"Epoch\", i+1)\n",
    "        print(\"Time: %.3f seconds\" % (time.time() - t0))\n",
    "        print(\"Validation Loss =\", val_loss)\n",
    "        print(\"Validation Accuracy =\", val_acc)\n",
    "        print(\"\")\n",
    "```\n",
    "\n",
    "This is the main training procedure. As we can see we run __train_op__ on each batch. Additionally, before each epoch the training set is shuffled using __shuffle__. At the end of each epoch the validation loss and accuracy are recorded and printed out.\n",
    "\n",
    "Running the above code results in the following results after 10 epochs:\n",
    "```Python\n",
    "Epoch 10\n",
    "Time: 53.402 seconds\n",
    "Validation Loss = 0.126141663276\n",
    "Validation Accuracy = 0.966069240196\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
