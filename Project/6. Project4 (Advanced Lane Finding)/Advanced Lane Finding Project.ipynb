{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Calibration and Distorsion Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:09,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "def camera_calibration(gray_image_data):\n",
    "    images = np.copy(gray_image_data)\n",
    "    \n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in tqdm(enumerate(images)):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "            write_name = './camera_cal/corners_found'+str(idx)+'.jpg'\n",
    "            cv2.imwrite(write_name, img)\n",
    "            #cv2.imshow('img', img)\n",
    "            #cv2.waitKey(500)\n",
    "\n",
    "            # Do camera calibration given object points and image points\n",
    "            img_size = (img.shape[1], img.shape[0])\n",
    "            ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "            \n",
    "            return ret, mtx, dist, rvect, tvecs\n",
    "\n",
    "def distortion_correction(image_data, mtx, dist):\n",
    "    img = np.copy(image_data)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    cv2.imwrite('./camera_cal/undist'+str(idx)+'.jpg', dst)\n",
    "\n",
    "for idx, fname in tqdm(enumerate(images)):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Test undistortion on an image\n",
    "#img = cv2.imread('./camera_cal/calibration1.jpg')\n",
    "#img_size = (img.shape[1], img.shape[0])\n",
    "        \n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "#print(dist_pickle)\n",
    "pickle.dump( dist_pickle, open( \"./camera_cal/calibration_ pickle.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perspective_transform(image_data):\n",
    "    img = np.copy(image_data)\n",
    "    # work on defining perspective transformation area\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    bot_width = 0.45#0.4#0.8#0.76 # percent of bottom trapezoid height\n",
    "    mid_width = 0.12#0.04#0.2#0.08 # percent of middle trapezoid height\n",
    "    height_pct = 0.66#0.66#0.62 # percent for trapezoid height\n",
    "    bottom_trim = 0.935#0.935 # percent from top to bottom to avoid car hood\n",
    "\n",
    "    src = np.float32([[img.shape[1]*(0.5-mid_width/2), img.shape[0]*height_pct], [img.shape[1]*(0.5+mid_width/2), img.shape[0]*height_pct], \n",
    "                    [img.shape[1]*(0.5+bot_width/2), img.shape[0]*bottom_trim], [img.shape[1]*(0.5-bot_width/2),  img.shape[0]*bottom_trim]])\n",
    "    \n",
    "    offset = img_size[0]*0.25#0.3#0.15#0.25\n",
    "    dst = np.float32([[offset, 0], [img_size[0]-offset, 0], [img_size[0]-offset, img_size[1]], [offset, img_size[1]]])\n",
    "    \n",
    "    # perform the transform\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst,src)\n",
    "    warped = cv2.warpPerspective(preprocessed_img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    write_name = './test_images/2. warped' + str(idx+1) + '.jpg'\n",
    "    cv2.imwrite(write_name, warped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
