{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from skimage import exposure\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "filePath = 'traffic-signs-data/'\n",
    "training_file = filePath+'train.p'\n",
    "validation_file= filePath+'valid.p'\n",
    "testing_file = filePath+'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: x=34799, y=34799\n",
      "Number of validation examples: x=4410, y=4410\n",
      "Number of testing examples:  x=12630, y=12630\n",
      "Image data shape = (32, 32)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "# TODO: Number of validation examples\n",
    "n_validation = X_valid.shape[0]\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "labels = pd.read_csv('signnames.csv')\n",
    "n_classes = len(labels)\n",
    "\n",
    "print(\"Number of training examples: x={0}, y={1}\".format(n_train, y_train.shape[0]))\n",
    "print(\"Number of validation examples: x={0}, y={1}\".format(n_validation, y_valid.shape[0]))\n",
    "print(\"Number of testing examples:  x={0}, y={1}\".format(n_test, y_test.shape[0]))\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Include an exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.8 ms, sys: 3.56 ms, total: 12.4 ms\n",
      "Wall time: 11.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train_df = pd.DataFrame(data=y_train, columns=['ClassId'])\n",
    "y_valid_df = pd.DataFrame(data=y_valid, columns=['ClassId'])\n",
    "y_test_df = pd.DataFrame(data=y_test, columns=['ClassId'])\n",
    "\n",
    "grouped_train_index = y_train_df.groupby('ClassId')\n",
    "grouped_valid_index = y_valid_df.groupby('ClassId')\n",
    "grouped_test_index = y_test_df.groupby('ClassId')\n",
    "\n",
    "## Get the first index images in each class\n",
    "firstTrainDataForEachClass = grouped_train_index.head(1).sort_values('ClassId').reset_index()\n",
    "#print(firstTrainDataForEachClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "### Pre-process the Data Set (Self: normalization, grayscale, etc.)\n",
    "### 1. Grayscale: OpenCV, 2. Normalization: OpenCV, 3. Enhance Contrast: OpenCV, 4. so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Preprocess the data here. It is required to normalize the data. Other preprocessing steps could include \n",
    "### converting to grayscale, etc.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "## Change to gray scale\n",
    "def colourToGrey(images):\n",
    "    gray = np.zeros([len(images), 32, 32], dtype=np.float64)\n",
    "    for idx in tqdm(range(len(images))):\n",
    "        gray[idx] = 0.299 * images[idx, :, :, 0] + 0.587 * images[idx, :, :, 1] + 0.114 * images[idx, :, :, 2]\n",
    "    return gray\n",
    "\n",
    "## Normalisation\n",
    "def normaliseGrayImages(images):\n",
    "    norm = copy.copy(images)\n",
    "    \n",
    "    for idx, img in tqdm(enumerate(images)):\n",
    "        norm[idx] = preprocessing.normalize(norm[idx], norm='l2')\n",
    "    return norm\n",
    "\n",
    "## Enhance Contrast using histogram equalization\n",
    "def enhanceContrastOfImage(img):\n",
    "    return exposure.equalize_adapthist(img)\n",
    "    '''\n",
    "    yuv_img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    yuv_img[:,:,0] = cv2.equalizeHist(yuv_img[:,:,0])\n",
    "    return cv2.cvtColor(yuv_img, cv2.COLOR_YUV2RGB)\n",
    "    '''\n",
    "    '''\n",
    "    if np.mean(img) < 50:\n",
    "        brightImage = img.copy()\n",
    "        brightImage[:,:,0] = cv2.equalizeHist(img[:,:,0])\n",
    "        brightImage[:,:,1] = cv2.equalizeHist(img[:,:,1])\n",
    "        brightImage[:,:,2] = cv2.equalizeHist(img[:,:,2])\n",
    "        return brightImage\n",
    "    return img\n",
    "    '''\n",
    "\n",
    "\n",
    "def sharpenImage(img):\n",
    "    kernelOfSharpener = np.array([[-1,-1,-1,-1,-1], \n",
    "                                 [-1,2,2,2,-1], \n",
    "                                 [-1,2,8,2,-1],\n",
    "                                 [-1,2,2,2,-1],\n",
    "                                 [-1,-1,-1,-1,-1]]) / 8.0\n",
    "    return cv2.filter2D(img, -1, kernelOfSharpener)\n",
    "\n",
    "def affineTransformation(img):\n",
    "    row, column = X_train[8000].shape[:2]\n",
    "    sourcePoints = np.float32([[0, 0], [column-1, 0], [0, row-1]])\n",
    "\n",
    "    destinationPoints = np.float32([[np.random.uniform(low=0., high=0.2, size=1)[0]*(row-1), np.random.uniform(low=0., high=0.2, size=1)[0]*(column-1)], \n",
    "                                    [np.random.uniform(low=0.7, high=1, size=1)[0]*(row-1), np.random.uniform(low=0., high=0.2, size=1)[0]*(column-1)], \n",
    "                                    [np.random.uniform(low=0., high=0.2, size=1)[0]*(row-1), np.random.uniform(low=0.7, high=1, size=1)[0]*(column-1)]])\n",
    "\n",
    "    affine_matrix = cv2.getAffineTransform(sourcePoints, destinationPoints)\n",
    "    #img_output = cv2.warpAffine(X_train[8000], affine_matrix, (row, column))\n",
    "    \n",
    "    return cv2.warpAffine(img, affine_matrix, (row, column))\n",
    "\n",
    "def translateImageWithRandomDistance(img):\n",
    "    row, column = img.shape[:2]\n",
    "    matrixForTranslation = np.array([ [1, 0, np.random.randint(low=-5, high=5)], [0, 1, np.random.randint(low=-5, high=5)] ], dtype=float)\n",
    "    translatedImage = cv2.warpAffine(img, matrixForTranslation, (row, column))\n",
    "    return translatedImage\n",
    "\n",
    "def rotateImageWithRandomAngle(img):\n",
    "    row, column = img.shape[:2]\n",
    "    matrixForRotation = cv2.getRotationMatrix2D((column/2, row/2), np.random.randint(low=-35, high=35), 1)\n",
    "    rotatedImage = cv2.warpAffine(img, matrixForRotation, (row, column))\n",
    "    return rotatedImage\n",
    "\n",
    "def makeBallanceBetweenClasses(grouped_y_index=None, xData=None, yData=None):\n",
    "    ## balance the number of samples in classes\n",
    "    maxSampleNumbersAmongClasses = max(grouped_y_index.size())\n",
    "    argmaxSampleNumbersAmongClasses = np.argmax(grouped_y_index.size())\n",
    "\n",
    "    for class_idx, value in tqdm(grouped_y_index.groups.items()):\n",
    "        '''\n",
    "        if class_idx>1:\n",
    "            break\n",
    "        '''\n",
    "        necessaryNum = maxSampleNumbersAmongClasses - len(value)\n",
    "        randomImgInAClass = xData[np.random.choice(grouped_y_index.groups[class_idx].values, necessaryNum)]\n",
    "\n",
    "        augmented_y = np.ones(necessaryNum) * class_idx\n",
    "\n",
    "        for idx, img in enumerate(randomImgInAClass):\n",
    "            randomImgInAClass[idx] = transAndRotate(img)\n",
    "            #randomImgInAClass[idx] = transAndRotate(colourToGrey(img))\n",
    "        xData = np.vstack([xData, randomImgInAClass])\n",
    "        yData = np.append(yData, augmented_y)\n",
    "        \n",
    "    return xData, yData\n",
    "\n",
    "def transAndRotate(img):\n",
    "    switch = np.random.choice(('affine', 'rotate', 'translate', 'rotate+translate'), size=1)[0] # choose one among three strings\n",
    "    #print(switch)\n",
    "    if switch == 'affine':\n",
    "        return affineTransformation(img)\n",
    "    if switch == 'rotate':\n",
    "        return rotateImageWithRandomAngle(img)\n",
    "    if switch == 'translate':\n",
    "        return translateImageWithRandomDistance(img)\n",
    "    if switch == 'rotate+translate':\n",
    "        return translateImageWithRandomDistance(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def saveToPickle(data, file_name=None, folder_path=None):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        #print(\"Create \\\"preprocessed-data\\\" folder\")\n",
    "        os.mkdir(folder_path)\n",
    "    else:\n",
    "        print(\"\\\"preprocessed-data\\\" folder already exist\")\n",
    "\n",
    "    file_name = folder_path + file_name\n",
    "    if not os.path.exists(file_name):\n",
    "        try:\n",
    "            with open(file_name, 'wb') as f:\n",
    "                pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "                print(\"Create\", file_name)\n",
    "        except Exception as e:\n",
    "            print('Error: unable to save data to', file_name, 'because', e)\n",
    "            \n",
    "def loadPickle(file_name=None, folder_path=None):\n",
    "    file = folder_path + file_name\n",
    "    #print('Load')\n",
    "    if os.path.exists(file):\n",
    "        try:\n",
    "            with open(file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "                print(\"Open\", file)\n",
    "        except Exception as e:\n",
    "            print('Error: unable to open data to', file, 'because', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Colour to Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34799/34799 [00:01<00:00, 19891.74it/s]\n",
      "100%|██████████| 4410/4410 [00:00<00:00, 23383.94it/s]\n",
      "100%|██████████| 12630/12630 [00:00<00:00, 24101.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# colour to gray\n",
    "augmented_X_train = colourToGrey(X_train)\n",
    "augmented_X_valid = colourToGrey(X_valid)\n",
    "augmented_X_test = colourToGrey(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x140f628d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFJCAYAAAASfw+VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x140dd8240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(augmented_X_train[7809], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Sharpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "augmented_X_train = sharpenImage(augmented_X_train)\n",
    "augmented_X_valid = sharpenImage(augmented_X_valid)\n",
    "augmented_X_test = sharpenImage(augmented_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(augmented_X_train[7809], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Normalisation: OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# normalisation\n",
    "augmented_X_train = normaliseGrayImages(augmented_X_train)\n",
    "augmented_X_valid = normaliseGrayImages(augmented_X_valid)\n",
    "augmented_X_test = normaliseGrayImages(augmented_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(augmented_X_train[7809], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Enhance Contrast: OpenCV histogram equlization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for idx in tqdm(range(augmented_X_train.shape[0])):\n",
    "    augmented_X_train[idx] = enhanceContrastOfImage(augmented_X_train[idx])\n",
    "\n",
    "for idx in tqdm(range(augmented_X_valid.shape[0])):\n",
    "    augmented_X_valid[idx] = enhanceContrastOfImage(augmented_X_valid[idx])\n",
    "\n",
    "for idx in tqdm(range(augmented_X_test.shape[0])):\n",
    "    augmented_X_test[idx] = enhanceContrastOfImage(augmented_X_test[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(augmented_X_train[7809], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Augmentation and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "augmented_X_train, augmented_y_train = makeBallanceBetweenClasses(grouped_train_index, X_train, y_train)\n",
    "augmented_X_valid, augmented_y_valid = makeBallanceBetweenClasses(grouped_valid_index, X_valid, y_valid)\n",
    "augmented_X_test, augmented_y_test = makeBallanceBetweenClasses(grouped_test_index, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saveToPickle(augmented_X_train, file_name='augmented_X_train.p', folder_path=\"./preprocessed-data/\")\n",
    "saveToPickle(augmented_y_train, file_name='augmented_y_train.p', folder_path=\"./preprocessed-data/\")\n",
    "\n",
    "saveToPickle(augmented_X_valid, file_name='augmented_X_valid.p', folder_path=\"./preprocessed-data/\")\n",
    "saveToPickle(augmented_y_valid, file_name='augmented_y_valid.p', folder_path=\"./preprocessed-data/\")\n",
    "\n",
    "saveToPickle(augmented_X_test, file_name='augmented_X_test.p', folder_path=\"./preprocessed-data/\")\n",
    "saveToPickle(augmented_y_test, file_name='augmented_y_test.p', folder_path=\"./preprocessed-data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "augmented_X_train = loadPickle(file_name='augmented_X_train.p', folder_path='./preprocessed-data/')\n",
    "augmented_y_train = loadPickle(file_name='augmented_y_train.p', folder_path='./preprocessed-data/')\n",
    "\n",
    "augmented_X_valid = loadPickle(file_name='augmented_X_valid.p', folder_path='./preprocessed-data/')\n",
    "augmented_y_valid = loadPickle(file_name='augmented_y_valid.p', folder_path='./preprocessed-data/')\n",
    "\n",
    "augmented_X_test = loadPickle(file_name='augmented_X_test.p', folder_path='./preprocessed-data/')\n",
    "augmented_y_test = loadPickle(file_name='augmented_y_test.p', folder_path='./preprocessed-data/')\n",
    "\n",
    "print('The shape of the loaded processed X train dataset:', augmented_X_train.shape)\n",
    "print('The shape of the loaded processed y train dataset:', augmented_y_train.shape)\n",
    "\n",
    "print('The shape of the loaded processed X valid dataset:', augmented_X_valid.shape)\n",
    "print('The shape of the loaded processed y valid dataset:', augmented_y_valid.shape)\n",
    "\n",
    "print('The shape of the loaded processed X test dataset:', augmented_X_test.shape)\n",
    "print('The shape of the loaded processed y test dataset:', augmented_y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
