{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from PIL import Image\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "filePath = 'traffic-signs-data/'\n",
    "training_file = filePath+'train.p'\n",
    "validation_file= filePath+'valid.p'\n",
    "testing_file = filePath+'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: x=34799, y=34799\n",
      "Number of validation examples: x=4410, y=4410\n",
      "Number of testing examples:  x=12630, y=12630\n",
      "Image data shape = (32, 32)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "# TODO: Number of validation examples\n",
    "n_validation = X_valid.shape[0]\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "labels = pd.read_csv('signnames.csv')\n",
    "n_classes = len(labels)\n",
    "\n",
    "print(\"Number of training examples: x={0}, y={1}\".format(n_train, y_train.shape[0]))\n",
    "print(\"Number of validation examples: x={0}, y={1}\".format(n_validation, y_valid.shape[0]))\n",
    "print(\"Number of testing examples:  x={0}, y={1}\".format(n_test, y_test.shape[0]))\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Include an exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.75 ms, sys: 3.06 ms, total: 11.8 ms\n",
      "Wall time: 10.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train_df = pd.DataFrame(data=y_train, columns=['ClassId'])\n",
    "y_valid_df = pd.DataFrame(data=y_valid, columns=['ClassId'])\n",
    "y_test_df = pd.DataFrame(data=y_test, columns=['ClassId'])\n",
    "\n",
    "grouped_train_index = y_train_df.groupby('ClassId')\n",
    "grouped_valid_index = y_valid_df.groupby('ClassId')\n",
    "grouped_test_index = y_test_df.groupby('ClassId')\n",
    "\n",
    "## Get the first index images in each class\n",
    "firstTrainDataForEachClass = grouped_train_index.head(1).sort_values('ClassId').reset_index()\n",
    "#print(firstTrainDataForEachClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "### Pre-process the Data Set (Self: normalization, grayscale, etc.)\n",
    "### 1. Grayscale: OpenCV, 2. Normalization: OpenCV, 3. Enhance Contrast: OpenCV, 4. so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Preprocess the data here. It is required to normalize the data. Other preprocessing steps could include \n",
    "### converting to grayscale, etc.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "## Normalisation\n",
    "def normaliseColourImages(images):\n",
    "    images = images.astype(np.float32)\n",
    "    for idx, img in tqdm(enumerate(images)):\n",
    "        images[idx] = cv2.normalize(img, dst=img, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    return images\n",
    "\n",
    "## Enhance Contrast using histogram equalization\n",
    "def enhanceContrastOfImage(img):\n",
    "    yuv_img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    yuv_img[:,:,0] = cv2.equalizeHist(yuv_img[:,:,0])\n",
    "    return cv2.cvtColor(yuv_img, cv2.COLOR_YUV2RGB)\n",
    "\n",
    "    '''\n",
    "    if np.mean(img) < 50:\n",
    "        brightImage = img.copy()\n",
    "        brightImage[:,:,0] = cv2.equalizeHist(img[:,:,0])\n",
    "        brightImage[:,:,1] = cv2.equalizeHist(img[:,:,1])\n",
    "        brightImage[:,:,2] = cv2.equalizeHist(img[:,:,2])\n",
    "        return brightImage\n",
    "    return img\n",
    "    '''\n",
    "\n",
    "\n",
    "def sharpenImage(img):\n",
    "    kernelOfSharpener = np.array([[-1,-1,-1,-1,-1], \n",
    "                                 [-1,2,2,2,-1], \n",
    "                                 [-1,2,8,2,-1],\n",
    "                                 [-1,2,2,2,-1],\n",
    "                                 [-1,-1,-1,-1,-1]]) / 8.0\n",
    "    return cv2.filter2D(img, -1, kernelOfSharpener)\n",
    "\n",
    "def affineTransformation(img):\n",
    "    row, column = X_train[8000].shape[:2]\n",
    "    sourcePoints = np.float32([[0, 0], [column-1, 0], [0, row-1]])\n",
    "\n",
    "    destinationPoints = np.float32([[np.random.uniform(low=0., high=0.2, size=1)[0]*(row-1), np.random.uniform(low=0., high=0.2, size=1)[0]*(column-1)], \n",
    "                                    [np.random.uniform(low=0.7, high=1, size=1)[0]*(row-1), np.random.uniform(low=0., high=0.2, size=1)[0]*(column-1)], \n",
    "                                    [np.random.uniform(low=0., high=0.2, size=1)[0]*(row-1), np.random.uniform(low=0.7, high=1, size=1)[0]*(column-1)]])\n",
    "\n",
    "    affine_matrix = cv2.getAffineTransform(sourcePoints, destinationPoints)\n",
    "    #img_output = cv2.warpAffine(X_train[8000], affine_matrix, (row, column))\n",
    "    \n",
    "    return cv2.warpAffine(img, affine_matrix, (row, column))\n",
    "\n",
    "def translateImageWithRandomDistance(img):\n",
    "    row, column = img.shape[:2]\n",
    "    matrixForTranslation = np.array([ [1, 0, np.random.randint(low=-5, high=5)], [0, 1, np.random.randint(low=-5, high=5)] ], dtype=float)\n",
    "    translatedImage = cv2.warpAffine(img, matrixForTranslation, (row, column))\n",
    "    return translatedImage\n",
    "\n",
    "def rotateImageWithRandomAngle(img):\n",
    "    row, column = img.shape[:2]\n",
    "    matrixForRotation = cv2.getRotationMatrix2D((column/2, row/2), np.random.randint(low=-35, high=35), 1)\n",
    "    rotatedImage = cv2.warpAffine(img, matrixForRotation, (row, column))\n",
    "    return rotatedImage\n",
    "\n",
    "def makeBallanceBetweenClasses(grouped_y_index=None, xData=None, yData=None):\n",
    "    ## balance the number of samples in classes\n",
    "    maxSampleNumbersAmongClasses = max(grouped_y_index.size())\n",
    "    argmaxSampleNumbersAmongClasses = np.argmax(grouped_y_index.size())\n",
    "\n",
    "    for class_idx, value in tqdm(grouped_y_index.groups.items()):\n",
    "        '''\n",
    "        if class_idx>1:\n",
    "            break\n",
    "        '''\n",
    "        necessaryNum = maxSampleNumbersAmongClasses - len(value)\n",
    "        randomImgInAClass = xData[np.random.choice(grouped_y_index.groups[class_idx].values, necessaryNum)]\n",
    "\n",
    "        augmented_y = np.ones(necessaryNum) * class_idx\n",
    "\n",
    "        for idx, img in enumerate(randomImgInAClass):\n",
    "            randomImgInAClass[idx] = transAndRotate(img)\n",
    "            #randomImgInAClass[idx] = transAndRotate(colourToGrey(img))\n",
    "        xData = np.vstack([xData, randomImgInAClass])\n",
    "        yData = np.append(yData, augmented_y)\n",
    "        \n",
    "    return xData, yData\n",
    "\n",
    "def transAndRotate(img):\n",
    "    switch = np.random.choice(('affine', 'rotate', 'translate', 'rotate+translate'), size=1)[0] # choose one among three strings\n",
    "    #print(switch)\n",
    "    if switch == 'affine':\n",
    "        return affineTransformation(img)\n",
    "    if switch == 'rotate':\n",
    "        return rotateImageWithRandomAngle(img)\n",
    "    if switch == 'translate':\n",
    "        return translateImageWithRandomDistance(img)\n",
    "    if switch == 'rotate+translate':\n",
    "        return translateImageWithRandomDistance(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def saveToPickle(data, file_name=None, folder_path=None):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        #print(\"Create \\\"preprocessed-data\\\" folder\")\n",
    "        os.mkdir(folder_path)\n",
    "    else:\n",
    "        print(\"\\\"preprocessed-data\\\" folder already exist\")\n",
    "\n",
    "    file_name = folder_path + file_name\n",
    "    if not os.path.exists(file_name):\n",
    "        try:\n",
    "            with open(file_name, 'wb') as f:\n",
    "                pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "                print(\"Create\", file_name)\n",
    "        except Exception as e:\n",
    "            print('Error: unable to save data to', file_name, 'because', e)\n",
    "            \n",
    "def loadPickle(file_name=None, folder_path=None):\n",
    "    file = folder_path + file_name\n",
    "    #print('Load')\n",
    "    if os.path.exists(file):\n",
    "        try:\n",
    "            with open(file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "                print(\"Open\", file)\n",
    "        except Exception as e:\n",
    "            print('Error: unable to open data to', file, 'because', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhance Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34799/34799 [00:01<00:00, 22237.77it/s]\n",
      "100%|██████████| 4410/4410 [00:00<00:00, 23762.17it/s]\n",
      "100%|██████████| 12630/12630 [00:00<00:00, 22786.78it/s]\n"
     ]
    }
   ],
   "source": [
    "augmented_X_train = np.zeros(X_train.shape, dtype=np.uint8)\n",
    "augmented_X_valid = np.zeros(X_valid.shape, dtype=np.uint8)\n",
    "augmented_X_test = np.zeros(X_test.shape, dtype=np.uint8)\n",
    "\n",
    "for idx in tqdm(range(X_train.shape[0])):\n",
    "    augmented_X_train[idx] = enhanceContrastOfImage(X_train[idx])\n",
    "\n",
    "for idx in tqdm(range(X_valid.shape[0])):\n",
    "    augmented_X_valid[idx] = enhanceContrastOfImage(X_valid[idx])\n",
    "\n",
    "for idx in tqdm(range(X_test.shape[0])):\n",
    "    augmented_X_test[idx] = enhanceContrastOfImage(X_test[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x119f6c390>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFJCAYAAAASfw+VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103c91f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(augmented_X_train[7809], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Sharpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34799/34799 [00:02<00:00, 12781.84it/s]\n",
      "100%|██████████| 4410/4410 [00:00<00:00, 11765.93it/s]\n",
      "100%|██████████| 12630/12630 [00:01<00:00, 12241.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(range(X_train.shape[0])):\n",
    "    augmented_X_train[idx] = sharpenImage(X_train[idx])\n",
    "\n",
    "for idx in tqdm(range(X_valid.shape[0])):\n",
    "    augmented_X_valid[idx] = sharpenImage(X_valid[idx])\n",
    "\n",
    "for idx in tqdm(range(X_test.shape[0])):\n",
    "    augmented_X_test[idx] = sharpenImage(X_test[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(augmented_X_train[7809], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Normalisation: OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# normalisation\n",
    "augmented_X_train = normaliseColourImages(X_train)\n",
    "augmented_X_valid = normaliseColourImages(X_valid)\n",
    "augmented_X_test = normaliseColourImages(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(augmented_X_train[7809])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Augmentation and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "augmented_X_train, augmented_y_train = makeBallanceBetweenClasses(grouped_train_index, X_train, y_train)\n",
    "augmented_X_valid, augmented_y_valid = makeBallanceBetweenClasses(grouped_valid_index, X_valid, y_valid)\n",
    "augmented_X_test, augmented_y_test = makeBallanceBetweenClasses(grouped_test_index, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saveToPickle(augmented_X_train, file_name='augmented_X_train.p', folder_path=\"./preprocessed-data/\")\n",
    "saveToPickle(augmented_y_train, file_name='augmented_y_train.p', folder_path=\"./preprocessed-data/\")\n",
    "\n",
    "saveToPickle(augmented_X_valid, file_name='augmented_X_valid.p', folder_path=\"./preprocessed-data/\")\n",
    "saveToPickle(augmented_y_valid, file_name='augmented_y_valid.p', folder_path=\"./preprocessed-data/\")\n",
    "\n",
    "saveToPickle(augmented_X_test, file_name='augmented_X_test.p', folder_path=\"./preprocessed-data/\")\n",
    "saveToPickle(augmented_y_test, file_name='augmented_y_test.p', folder_path=\"./preprocessed-data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "augmented_X_train = loadPickle(file_name='augmented_X_train.p', folder_path='./preprocessed-data/')\n",
    "augmented_y_train = loadPickle(file_name='augmented_y_train.p', folder_path='./preprocessed-data/')\n",
    "\n",
    "augmented_X_valid = loadPickle(file_name='augmented_X_valid.p', folder_path='./preprocessed-data/')\n",
    "augmented_y_valid = loadPickle(file_name='augmented_y_valid.p', folder_path='./preprocessed-data/')\n",
    "\n",
    "augmented_X_test = loadPickle(file_name='augmented_X_test.p', folder_path='./preprocessed-data/')\n",
    "augmented_y_test = loadPickle(file_name='augmented_y_test.p', folder_path='./preprocessed-data/')\n",
    "\n",
    "print('The shape of the loaded processed X train dataset:', augmented_X_train.shape)\n",
    "print('The shape of the loaded processed y train dataset:', augmented_y_train.shape)\n",
    "\n",
    "print('The shape of the loaded processed X valid dataset:', augmented_X_valid.shape)\n",
    "print('The shape of the loaded processed y valid dataset:', augmented_y_valid.shape)\n",
    "\n",
    "print('The shape of the loaded processed X test dataset:', augmented_X_test.shape)\n",
    "print('The shape of the loaded processed y test dataset:', augmented_y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
