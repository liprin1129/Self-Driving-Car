{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from PIL import Image\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "filePath = 'traffic-signs-data/'\n",
    "training_file = filePath+'train.p'\n",
    "validation_file= filePath+'valid.p'\n",
    "testing_file = filePath+'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: x=34799, y=34799\n",
      "Number of validation examples: x=4410, y=4410\n",
      "Number of testing examples:  x=12630, y=12630\n",
      "Image data shape = (32, 32)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "# TODO: Number of validation examples\n",
    "n_validation = X_valid.shape[0]\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "labels = pd.read_csv('signnames.csv')\n",
    "n_classes = len(labels)\n",
    "\n",
    "print(\"Number of training examples: x={0}, y={1}\".format(n_train, y_train.shape[0]))\n",
    "print(\"Number of validation examples: x={0}, y={1}\".format(n_validation, y_valid.shape[0]))\n",
    "print(\"Number of testing examples:  x={0}, y={1}\".format(n_test, y_test.shape[0]))\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include an exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train_df = pd.DataFrame(data=y_train, columns=['ClassId'])\n",
    "y_valid_df = pd.DataFrame(data=y_valid, columns=['ClassId'])\n",
    "y_test_df = pd.DataFrame(data=y_test, columns=['ClassId'])\n",
    "\n",
    "grouped_train_index = y_train_df.groupby('ClassId')\n",
    "grouped_valid_index = y_valid_df.groupby('ClassId')\n",
    "grouped_test_index = y_test_df.groupby('ClassId')\n",
    "\n",
    "## Get the first index images in each class\n",
    "firstTrainDataForEachClass = grouped_train_index.head(1).sort_values('ClassId').reset_index()\n",
    "#print(firstTrainDataForEachClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "### Pre-process the Data Set (Self: normalization, grayscale, etc.)\n",
    "### 1. Grayscale: OpenCV, 2. Normalization: OpenCV, 3. Enhance Contrast: OpenCV, 4. so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Preprocess the data here. It is required to normalize the data. Other preprocessing steps could include \n",
    "### converting to grayscale, etc.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "## Normalisation\n",
    "def normaliseColourImages(images):\n",
    "    images = images.astype(np.float32)\n",
    "    for idx, img in tqdm(enumerate(images)):\n",
    "        images[idx] = cv2.normalize(img, dst=img, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    return images\n",
    "\n",
    "## Enhance Contrast using histogram equalization\n",
    "def enhanceContrastOfImage(img):\n",
    "    return cv2.equalizeHist(img)\n",
    "    '''\n",
    "    yuv_img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    yuv_img[:,:,0] = cv2.equalizeHist(yuv_img[:,:,0])\n",
    "    return cv2.cvtColor(yuv_img, cv2.COLOR_YUV2RGB)\n",
    "    '''\n",
    "    '''\n",
    "    if np.mean(img) < 50:\n",
    "        brightImage = img.copy()\n",
    "        brightImage[:,:,0] = cv2.equalizeHist(img[:,:,0])\n",
    "        brightImage[:,:,1] = cv2.equalizeHist(img[:,:,1])\n",
    "        brightImage[:,:,2] = cv2.equalizeHist(img[:,:,2])\n",
    "        return brightImage\n",
    "    return img\n",
    "    '''\n",
    "\n",
    "\n",
    "def sharpenImage(img):\n",
    "    kernelOfSharpener = np.array([[-1,-1,-1,-1,-1], \n",
    "                                 [-1,2,2,2,-1], \n",
    "                                 [-1,2,8,2,-1],\n",
    "                                 [-1,2,2,2,-1],\n",
    "                                 [-1,-1,-1,-1,-1]]) / 8.0\n",
    "    return cv2.filter2D(img, -1, kernelOfSharpener)\n",
    "\n",
    "def affineTransformation(img):\n",
    "    row, column = X_train[8000].shape[:2]\n",
    "    sourcePoints = np.float32([[0, 0], [column-1, 0], [0, row-1]])\n",
    "\n",
    "    destinationPoints = np.float32([[np.random.uniform(low=0., high=0.2, size=1)[0]*(row-1), np.random.uniform(low=0., high=0.2, size=1)[0]*(column-1)], \n",
    "                                    [np.random.uniform(low=0.7, high=1, size=1)[0]*(row-1), np.random.uniform(low=0., high=0.2, size=1)[0]*(column-1)], \n",
    "                                    [np.random.uniform(low=0., high=0.2, size=1)[0]*(row-1), np.random.uniform(low=0.7, high=1, size=1)[0]*(column-1)]])\n",
    "\n",
    "    affine_matrix = cv2.getAffineTransform(sourcePoints, destinationPoints)\n",
    "    #img_output = cv2.warpAffine(X_train[8000], affine_matrix, (row, column))\n",
    "    \n",
    "    return cv2.warpAffine(img, affine_matrix, (row, column))\n",
    "\n",
    "def translateImageWithRandomDistance(img):\n",
    "    row, column = img.shape[:2]\n",
    "    matrixForTranslation = np.array([ [1, 0, np.random.randint(low=-5, high=5)], [0, 1, np.random.randint(low=-5, high=5)] ], dtype=float)\n",
    "    translatedImage = cv2.warpAffine(img, matrixForTranslation, (row, column))\n",
    "    return translatedImage\n",
    "\n",
    "def rotateImageWithRandomAngle(img):\n",
    "    row, column = img.shape[:2]\n",
    "    matrixForRotation = cv2.getRotationMatrix2D((column/2, row/2), np.random.randint(low=-35, high=35), 1)\n",
    "    rotatedImage = cv2.warpAffine(img, matrixForRotation, (row, column))\n",
    "    return rotatedImage\n",
    "\n",
    "def makeBallanceBetweenClasses(grouped_y_index=None, xData=None, yData=None):\n",
    "    ## balance the number of samples in classes\n",
    "    maxSampleNumbersAmongClasses = max(grouped_y_index.size())\n",
    "    argmaxSampleNumbersAmongClasses = np.argmax(grouped_y_index.size())\n",
    "\n",
    "    for class_idx, value in tqdm(grouped_y_index.groups.items()):\n",
    "        '''\n",
    "        if class_idx>1:\n",
    "            break\n",
    "        '''\n",
    "        necessaryNum = maxSampleNumbersAmongClasses - len(value)\n",
    "        randomImgInAClass = xData[np.random.choice(grouped_y_index.groups[class_idx].values, necessaryNum)]\n",
    "\n",
    "        augmented_y = np.ones(necessaryNum) * class_idx\n",
    "\n",
    "        for idx, img in enumerate(randomImgInAClass):\n",
    "            randomImgInAClass[idx] = transAndRotate(img)\n",
    "            #randomImgInAClass[idx] = transAndRotate(colourToGrey(img))\n",
    "        xData = np.vstack([xData, randomImgInAClass])\n",
    "        yData = np.append(yData, augmented_y)\n",
    "        \n",
    "    return xData, yData\n",
    "\n",
    "def transAndRotate(img):\n",
    "    switch = np.random.choice(('affine', 'rotate', 'translate', 'rotate+translate'), size=1)[0] # choose one among three strings\n",
    "    #print(switch)\n",
    "    if switch == 'affine':\n",
    "        return affineTransformation(img)\n",
    "    if switch == 'rotate':\n",
    "        return rotateImageWithRandomAngle(img)\n",
    "    if switch == 'translate':\n",
    "        return translateImageWithRandomDistance(img)\n",
    "    if switch == 'rotate+translate':\n",
    "        return translateImageWithRandomDistance(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveToPickle(data, file_name=None, folder_path=None):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        #print(\"Create \\\"preprocessed-data\\\" folder\")\n",
    "        os.mkdir(folder_path)\n",
    "    else:\n",
    "        print(\"\\\"preprocessed-data\\\" folder already exist\")\n",
    "\n",
    "    file_name = folder_path + file_name\n",
    "    if not os.path.exists(file_name):\n",
    "        try:\n",
    "            with open(file_name, 'wb') as f:\n",
    "                pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "                print(\"Create\", file_name)\n",
    "        except Exception as e:\n",
    "            print('Error: unable to save data to', file_name, 'because', e)\n",
    "            \n",
    "def loadPickle(file_name=None, folder_path=None):\n",
    "    file = folder_path + file_name\n",
    "    #print('Load')\n",
    "    if os.path.exists(file):\n",
    "        try:\n",
    "            with open(file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "                print(\"Open\", file)\n",
    "        except Exception as e:\n",
    "            print('Error: unable to open data to', file, 'because', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalisation: OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34799it [00:00, 210903.08it/s]\n",
      "4410it [00:00, 200456.04it/s]\n",
      "12630it [00:00, 210500.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# normalisation\n",
    "augmented_X_train = normaliseColourImages(X_train)\n",
    "augmented_X_valid = normaliseColourImages(X_valid)\n",
    "augmented_X_test = normaliseColourImages(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xf45da58>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFJCAYAAAASfw+VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUkSEoGApIkJQsBQRIShYiogQ/h91SHavb6jx7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf4290b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(augmented_X_train[7809])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 43/43 [00:14<00:00,  1.91it/s]\n",
      "100%|██████████████████████████████████████████| 43/43 [00:01<00:00, 21.68it/s]\n",
      "100%|██████████████████████████████████████████| 43/43 [00:05<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "augmented_X_train, augmented_y_train = makeBallanceBetweenClasses(grouped_train_index, augmented_X_train, y_train)\n",
    "augmented_X_valid, augmented_y_valid = makeBallanceBetweenClasses(grouped_valid_index, augmented_X_valid, y_valid)\n",
    "augmented_X_test, augmented_y_test = makeBallanceBetweenClasses(grouped_test_index, augmented_X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"preprocessed-data\" folder already exist\n",
      "Create ./preprocessed-data/augmented_X_train.p\n",
      "\"preprocessed-data\" folder already exist\n",
      "Create ./preprocessed-data/augmented_y_train.p\n",
      "\"preprocessed-data\" folder already exist\n",
      "Create ./preprocessed-data/augmented_X_valid.p\n",
      "\"preprocessed-data\" folder already exist\n",
      "Create ./preprocessed-data/augmented_y_valid.p\n",
      "\"preprocessed-data\" folder already exist\n",
      "Create ./preprocessed-data/augmented_X_test.p\n",
      "\"preprocessed-data\" folder already exist\n",
      "Create ./preprocessed-data/augmented_y_test.p\n"
     ]
    }
   ],
   "source": [
    "saveToPickle(augmented_X_train, file_name='augmented_X_train.p', folder_path=\"./preprocessed-data/\")\n",
    "saveToPickle(augmented_y_train, file_name='augmented_y_train.p', folder_path=\"./preprocessed-data/\")\n",
    "\n",
    "saveToPickle(augmented_X_valid, file_name='augmented_X_valid.p', folder_path=\"./preprocessed-data/\")\n",
    "saveToPickle(augmented_y_valid, file_name='augmented_y_valid.p', folder_path=\"./preprocessed-data/\")\n",
    "\n",
    "saveToPickle(augmented_X_test, file_name='augmented_X_test.p', folder_path=\"./preprocessed-data/\")\n",
    "saveToPickle(augmented_y_test, file_name='augmented_y_test.p', folder_path=\"./preprocessed-data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "augmented_X_train = loadPickle(file_name='augmented_X_train.p', folder_path='./preprocessed-data/')\n",
    "augmented_y_train = loadPickle(file_name='augmented_y_train.p', folder_path='./preprocessed-data/')\n",
    "\n",
    "augmented_X_valid = loadPickle(file_name='augmented_X_valid.p', folder_path='./preprocessed-data/')\n",
    "augmented_y_valid = loadPickle(file_name='augmented_y_valid.p', folder_path='./preprocessed-data/')\n",
    "\n",
    "augmented_X_test = loadPickle(file_name='augmented_X_test.p', folder_path='./preprocessed-data/')\n",
    "augmented_y_test = loadPickle(file_name='augmented_y_test.p', folder_path='./preprocessed-data/')\n",
    "\n",
    "print('The shape of the loaded processed X train dataset:', augmented_X_train.shape)\n",
    "print('The shape of the loaded processed y train dataset:', augmented_y_train.shape)\n",
    "\n",
    "print('The shape of the loaded processed X valid dataset:', augmented_X_valid.shape)\n",
    "print('The shape of the loaded processed y valid dataset:', augmented_y_valid.shape)\n",
    "\n",
    "print('The shape of the loaded processed X test dataset:', augmented_X_test.shape)\n",
    "print('The shape of the loaded processed y test dataset:', augmented_y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
