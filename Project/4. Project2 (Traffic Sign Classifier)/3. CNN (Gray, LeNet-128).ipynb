{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from PIL import Image\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveToPickle(data, file_name=None, folder_path=None):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        #print(\"Create \\\"preprocessed-data\\\" folder\")\n",
    "        os.mkdir(folder_path)\n",
    "    else:\n",
    "        print(\"\\\"preprocessed-data\\\" folder already exist\")\n",
    "\n",
    "    file_name = folder_path + file_name\n",
    "    if not os.path.exists(file_name):\n",
    "        try:\n",
    "            with open(file_name, 'wb') as f:\n",
    "                pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "                print(\"Create\", file_name)\n",
    "        except Exception as e:\n",
    "            print('Error: unable to save data to', file_name, 'because', e)\n",
    "            \n",
    "def loadPickle(file_name=None, folder_path=None):\n",
    "    file = folder_path + file_name\n",
    "    #print('Load')\n",
    "    if os.path.exists(file):\n",
    "        try:\n",
    "            with open(file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "                print(\"Open\", file)\n",
    "        except Exception as e:\n",
    "            print('Error: unable to open data to', file, 'because', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the loaded processed X train dataset: (86430, 32, 32)\n",
      "The shape of the loaded processed y train dataset: (86430,)\n",
      "The shape of the loaded processed X valid dataset: (10320, 32, 32)\n",
      "The shape of the loaded processed y valid dataset: (10320,)\n",
      "The shape of the loaded processed X test dataset: (32250, 32, 32)\n",
      "The shape of the loaded processed y test dataset: (32250,)\n"
     ]
    }
   ],
   "source": [
    "## Load\n",
    "augmented_X_train = loadPickle(file_name='augmented_X_train.p', folder_path='./preprocessed-data/')\n",
    "augmented_y_train = loadPickle(file_name='augmented_y_train.p', folder_path='./preprocessed-data/')\n",
    "\n",
    "augmented_X_valid = loadPickle(file_name='augmented_X_valid.p', folder_path='./preprocessed-data/')\n",
    "augmented_y_valid = loadPickle(file_name='augmented_y_valid.p', folder_path='./preprocessed-data/')\n",
    "\n",
    "augmented_X_test = loadPickle(file_name='augmented_X_test.p', folder_path='./preprocessed-data/')\n",
    "augmented_y_test = loadPickle(file_name='augmented_y_test.p', folder_path='./preprocessed-data/')\n",
    "\n",
    "print('The shape of the loaded processed X train dataset:', augmented_X_train.shape)\n",
    "print('The shape of the loaded processed y train dataset:', augmented_y_train.shape)\n",
    "\n",
    "print('The shape of the loaded processed X valid dataset:', augmented_X_valid.shape)\n",
    "print('The shape of the loaded processed y valid dataset:', augmented_y_valid.shape)\n",
    "\n",
    "print('The shape of the loaded processed X test dataset:', augmented_X_test.shape)\n",
    "print('The shape of the loaded processed y test dataset:', augmented_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    if batch_size > 0:\n",
    "        assert len(features) == len(labels)\n",
    "\n",
    "        output_batches = []\n",
    "        sample_size = len(features)\n",
    "\n",
    "        for start_i in range(0, sample_size, batch_size):\n",
    "            end_i = start_i + batch_size\n",
    "            batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "            output_batches.append(batch)\n",
    "    else:\n",
    "        assert len(features) == len(labels)\n",
    "        \n",
    "        output_batches = []\n",
    "        sample_size = len(features)\n",
    "        \n",
    "        for start in range(sample_size):\n",
    "            batch = [features[start], labels[start]]\n",
    "            output_batches.append(batch)\n",
    "            \n",
    "    return output_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    ## Layer 1: ##\n",
    "    # Convolutional. Input = 32x32x3. Output = 28x28x32.\n",
    "    conv_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 128), mean = mu, stddev = sigma))\n",
    "    conv_b = tf.Variable(tf.zeros(128))\n",
    "    conv   = tf.nn.conv2d(x, conv_W, strides=[1, 1, 1, 1], padding='VALID') + conv_b\n",
    "    \n",
    "    # Activation.\n",
    "    conv = tf.nn.relu(conv)\n",
    "    conv = tf.nn.dropout(conv, 0.7)\n",
    "    \n",
    "    #conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    ## Layer 2 ##\n",
    "    # Convolutional. Input = 32x32x3. Output = 28x28x32.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 128, 256), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(256))\n",
    "    conv1   = tf.nn.conv2d(conv, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1 = tf.nn.dropout(conv1, 0.7)\n",
    "\n",
    "    # Pooling. Input = 28x28x32. Output = 14x14x32.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    ## Layer 3: ##\n",
    "    # Convolutional. Output = 10x10x64.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 256, 384), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(384))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2 = tf.nn.dropout(conv2, 0.7)\n",
    "\n",
    "    # Pooling. Input = 10x10x64. Output = 5x5x64.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Flatten. Input = 5x5x64. Output = 1600.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    ## Layer 4: ## \n",
    "    # Fully Connected. Input = 1600. Output = 1200.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(6144, 3072), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(3072))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, 0.6)\n",
    "\n",
    "    ## Layer 5: ##\n",
    "    # Fully Connected. Input = 1200. Output = 840.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(3072, 1536), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(1536))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, 0.5)\n",
    "\n",
    "    # Layer 6: Fully Connected. Input = 840. Output = 43.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(1536, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "## Features and Labels\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Training Pipeline\n",
    "logits =  LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Model Evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data, batch_size, sess):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "\n",
    "    for batch_x, batch_y in tqdm(batches(batch_size, X_data, y_data)):\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "## Reshape dataset\n",
    "augmented_X_train = np.reshape(augmented_X_train, (len(augmented_X_train), 32, 32, 1))\n",
    "augmented_X_valid = np.reshape(augmented_X_valid, (len(augmented_X_valid), 32, 32, 1))\n",
    "augmented_X_test = np.reshape(augmented_X_test, (len(augmented_X_test), 32, 32, 1))\n",
    "print(augmented_X_train[:128].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1be87518>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFJCAYAAAASfw+VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npYgIQcVSRISgYikiQlCxFBEh/D85eRcJQ25kawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105b25f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(augmented_X_train[7806, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2701/2701 [05:47<00:00,  3.10it/s]\n",
      "100%|████████████████████████████████████████| 323/323 [00:13<00:00, 24.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.022\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████▋                            | 740/2701 [01:31<04:00,  8.15it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cf096781f7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mshuffle_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maugmented_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugmented_y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_operation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mvalidation_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maugmented_X_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugmented_y_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\gang.3DMEDIA\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py35TensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\gang.3DMEDIA\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py35TensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\gang.3DMEDIA\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py35TensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\gang.3DMEDIA\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py35TensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\gang.3DMEDIA\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py35TensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Train the Model\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf. global_variables_initializer())\n",
    "    num_examples = len(augmented_X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    #print()\n",
    "    for i in range(EPOCHS):\n",
    "        shuffle_X, shuffle_y = shuffle(augmented_X_train, augmented_y_train)\n",
    "        for batch_x, batch_y in tqdm(batches(BATCH_SIZE, shuffle_X, shuffle_y)):\n",
    "            session.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        validation_accuracy = evaluate(augmented_X_valid, augmented_y_valid, BATCH_SIZE, session)\n",
    "        print(\"EPOCH {0} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "    \n",
    "    saver.save(session, './CNN3')\n",
    "    print(\"Model Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
